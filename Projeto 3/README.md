# Projeto: Predi√ß√£o de Sinistros de Seguro Automotivo (Car Insurance Claim)

Este projeto detalha a constru√ß√£o de um pipeline completo de Machine Learning para prever a probabilidade de sinistro (`outcome`) em ap√≥lices de seguro automotivo. O processo abrange desde a limpeza de dados brutos (ETL), seguindo a arquitetura Medallion, at√© a sele√ß√£o e avalia√ß√£o de m√∫ltiplos modelos preditivos para identificar o de melhor performance.

---

### üìå Objetivos do Projeto

* Aplicar um pipeline ETL (Extra√ß√£o, Transforma√ß√£o, Carga) seguindo a **Arquitetura Medallion** (Bronze, Silver, Gold).
* Realizar o tratamento de **outliers** (usando IQR) e a imputa√ß√£o de **valores ausentes** (usando a m√©dia).
* Codificar vari√°veis categ√≥ricas (ordinais e nominais) para preparar os dados para modelagem.
* Conduzir uma An√°lise Explorat√≥ria de Dados (EDA) para identificar padr√µes e perfis de risco.
* Utilizar t√©cnicas de **Sele√ß√£o de Features** (Chi2, ANOVA, XGBoost) para otimizar o modelo e remover ru√≠dos.
* Treinar e comparar m√∫ltiplos algoritmos de classifica√ß√£o (DecisionTree, RandomForest, KNN, XGBoost) para selecionar o de melhor performance.

---

### üõ† Tecnologias Utilizadas

* PySpark (para salvamento nas camadas Medallion)
* Pandas e NumPy
* Scikit-learn (para pr√©-processamento, m√©tricas e modelagem)
* XGBoost
* Seaborn & Matplotlib
* Databricks

---

### üîç Insights Estrat√©gicos (EDA)

A an√°lise explorat√≥ria dos dados revelou padr√µes importantes sobre o risco de sinistro:

* **Idade e Experi√™ncia s√£o Fatores Chave:** Motoristas mais velhos e com mais tempo de habilita√ß√£o (`driving_experience`) apresentam uma correla√ß√£o negativa clara com a ocorr√™ncia de sinistros.
* **Ter Filhos N√£o Aumenta o Risco:** Embora a quantidade de filhos aumente com a idade, os sinistros diminuem. Isso sugere que motoristas com filhos podem ser mais prudentes ao volante.
* **Infra√ß√µes e Juventude:** O n√∫mero de infra√ß√µes por velocidade (`speeding_violations`) √© notavelmente maior em faixas et√°rias mais jovens, que tamb√©m concentram a maior propor√ß√£o de sinistros.
* **G√™nero n√£o √© Preditivo:** A distribui√ß√£o de sinistros √© quase id√™ntica entre homens e mulheres, n√£o sendo um fator decisivo isoladamente.

---

### üìÇ Arquivo Analisado

* `Car_Insurance_Claim.csv`

---

### ü§ñ Sele√ß√£o de Modelo

Quatro algoritmos de classifica√ß√£o foram treinados e avaliados. O **XGBoost Classifier** foi selecionado como o modelo final devido ao seu desempenho superior em todas as m√©tricas principais.

| Modelo | Acur√°cia | F1-Score | Recall | MAE |
| :--- | :---: | :---: | :---: | :---: |
| Decision Tree | 0.757 | 0.622 | 0.634 | 0.243 |
| Random Forest | 0.830 | 0.720 | 0.690 | 0.170 |
| K-Neighbors (KNN) | 0.812 | 0.694 | 0.679 | 0.188 |
| **XGBoost** | **0.840** | **0.740** | **0.740** | **0.160** |

**Conclus√£o:** O XGBoost apresentou o melhor equil√≠brio entre identificar corretamente os sinistros (Recall) e manter a precis√£o geral (Acur√°cia e F1-Score).

---

### ‚ñ∂ Execu√ß√£o

* O notebook foi desenvolvido em ambiente **Databricks**, utilizando **Python** e suas principais bibliotecas de Data Science (Pandas, Sklearn, XGBoost).
* O **PySpark** foi utilizado para a persist√™ncia dos dados limpos (Silver) e prontos para modelagem (Gold) em Delta Tables.

---

### üìÑ Licen√ßa

Este projeto destina-se a fins educacionais e de portf√≥lio.
